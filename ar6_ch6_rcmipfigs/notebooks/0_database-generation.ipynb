{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBS:\n",
    "This notebook is only slightly edited from Zebedee Nicholls notebook, see [here](https://gitlab.com/rcmip/rcmip/-/blob/master/notebooks/results/phase-1/database-generation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sarambl/PHD/IPCC/public/AR6_CH6_RCMIPFIGS/ar6_ch6_rcmipfigs\n",
      "/home/sarambl/PHD/IPCC/public/AR6_CH6_RCMIPFIGS/ar6_ch6_rcmipfigs/data_in\n"
     ]
    }
   ],
   "source": [
    "from ar6_ch6_rcmipfigs.constants import INPUT_DATA_DIR\n",
    "\n",
    "__depends__ = []\n",
    "__dest__ = [INPUT_DATA_DIR+\n",
    "    \"/data/database-results/phase-1/timestamp.txt\",\n",
    "    INPUT_DATA_DIR+\"/data/database-observations/timestamp.txt\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database generation\n",
    "\n",
    "\n",
    "In this notebook we process the data into a database we can later query to make plots/do analysis etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os.path\n",
    "import re\n",
    "from pathlib import Path\n",
    "from distutils.util import strtobool\n",
    "\n",
    "import pandas as pd\n",
    "import pyam\n",
    "import tqdm\n",
    "from scmdata import ScmDataFrame, df_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ar6_ch6_rcmipfigs.utils.database_generation import check_all_variables_and_units_as_in_protocol, \\\n",
    "    check_all_scenarios_as_in_protocol, unify_units, save_into_database, mce_get_quantile, hector_get_quantile\n",
    "\n",
    "TEST_RUN = strtobool(os.getenv(\"CI\", \"False\")) or False\n",
    "TEST_RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ar6_ch6_rcmipfigs.constants import  INPUT_DATA_DIR\n",
    "OUTPUT_DATABASE_PATH = os.path.join(INPUT_DATA_DIR, \"database-results\", \"phase-1/\")\n",
    "\n",
    "OBS_DATABASE_PATH = os.path.join(INPUT_DATA_DIR, \"database-observations/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from ar6_ch6_rcmipfigs.utils.misc_func import make_folders\n",
    "\n",
    "if not os.path.isdir(OUTPUT_DATABASE_PATH):\n",
    "    make_folders(OUTPUT_DATABASE_PATH)\n",
    "\n",
    "if not os.path.isdir(OBS_DATABASE_PATH):\n",
    "    make_folders(OBS_DATABASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO_PROTOCOL = os.path.join(INPUT_DATA_DIR, \"data\", \"protocol\", \"rcmip-emissions-annual-means.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_db = ScmDataFrame(SCENARIO_PROTOCOL)\n",
    "protocol_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_db[\"scenario\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PROTOCOL = os.path.join(INPUT_DATA_DIR,\n",
    "    \"data\",\n",
    "    \"submission-template\",\n",
    "    \"rcmip-data-submission-template.xlsx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_variables = pd.read_excel(DATA_PROTOCOL, sheet_name=\"variable_definitions\")\n",
    "protocol_variables.columns = protocol_variables.columns.str.lower()\n",
    "protocol_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_scenarios = pd.read_excel(\n",
    "    DATA_PROTOCOL, sheet_name=\"scenario_info\", skip_rows=2\n",
    ")\n",
    "protocol_scenarios.columns = protocol_scenarios.columns.str.lower()\n",
    "protocol_scenarios.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = os.path.join(INPUT_DATA_DIR, \"data\", \"results\", \"phase-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results_files = list(Path(RESULTS_PATH).rglob(\"*.csv\")) + list(\n",
    "    Path(RESULTS_PATH).rglob(\"*.xlsx\")\n",
    ")\n",
    "print(len(_results_files))\n",
    "sorted(_results_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_of_interest = [\n",
    "#    \".*acc2.*v2-0-1.*\",\n",
    "    \".*rcmip_phase-1_cicero-scm.*v5-0-0.*\",\n",
    "#    \".*escimo.*v2-0-1.*\",\n",
    "    \".*fair-1.5-default.*v1-0-1.csv\",\n",
    "#    \".*rcmip_phase-1_gir.*\",\n",
    "#    \".*greb.*v2-0-0.*\",\n",
    "#    \".*hector.*v2-0-0.*\",\n",
    "#    \".*MAGICC7.1.0aX-rcmip-phase-1.*\",\n",
    "    \".*rcmip_phase-1_magicc7.1.0.beta_v1-0-0.*\",\n",
    "#    \".*MAGICC7.1.0aX.*\",\n",
    "#    \".*mce.*v2-0-1.*\",\n",
    "#    \".*oscar-v3-0*v1-0-1.*\",\n",
    "    \".*oscar-v3-0.*v1-0-1.*\"\n",
    "#    \".*wasp.*v1-0-1.*\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_RUN:\n",
    "    model_of_interest = [\n",
    "        \".*escimo-phase-1-v2-0-1.*\",\n",
    "        \".*greb.*\",\n",
    "        \".*rcmip_phase-1_cicero-scm.*v5-0-0.*\",\n",
    "    ]\n",
    "\n",
    "results_files = [\n",
    "    str(p)\n",
    "    for p in _results_files\n",
    "    if any([bool(re.match(m, str(p))) for m in model_of_interest]) and \"$\" not in str(p)\n",
    "]\n",
    "print(len(results_files))\n",
    "sorted(results_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    str(p)\n",
    "    for p in results_files\n",
    "    if 'magicc' in str(p)] #for m in model_of_interest]) and \"$\" not in str(p)\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = []\n",
    "for rf in tqdm.tqdm_notebook(results_files):\n",
    "    if rf.endswith(\".csv\"):\n",
    "        loaded = ScmDataFrame(rf)\n",
    "    else:\n",
    "        loaded = ScmDataFrame(rf, sheet_name=\"your_data\")\n",
    "    db.append(loaded)\n",
    "\n",
    "db = df_append(db).timeseries().reset_index()\n",
    "db[\"unit\"] = db[\"unit\"].apply(\n",
    "    lambda x: x.replace(\"Dimensionless\", \"dimensionless\") if isinstance(x, str) else x\n",
    ")\n",
    "db = ScmDataFrame(db)\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.filter(climatemodel=\"*cicero*\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[\"climatemodel\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor quick fixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We relabel all the ssp370-lowNTCF data to remove ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.timeseries().reset_index()\n",
    "db[\"scenario\"] = db[\"scenario\"].apply(\n",
    "    lambda x: \"ssp370-lowNTCF-gidden\" if x == \"ssp370-lowNTCF\" else x\n",
    ")\n",
    "db[\"scenario\"] = db[\"scenario\"].apply(\n",
    "    lambda x: \"esm-ssp370-lowNTCF-gidden\" if x == \"esm-ssp370-lowNTCF\" else x\n",
    ")\n",
    "db[\"scenario\"] = db[\"scenario\"].apply(\n",
    "    lambda x: \"esm-ssp370-lowNTCF-gidden-allGHG\"\n",
    "    if x == \"esm-ssp370-lowNTCF-allGHG\"\n",
    "    else x\n",
    ")\n",
    "db = ScmDataFrame(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"ssp370-lowNTCF\" not in db[\"scenario\"].unique().tolist()\n",
    "assert \"esm-ssp370-lowNTCF\" not in db[\"scenario\"].unique().tolist()\n",
    "assert \"esm-ssp370-lowNTCF-allGHG\" not in db[\"scenario\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hector and MCE data is mislabelled so we do a quick fix here. I also have changed my mind about how to format the quantiles so tweak the FaIR and WASP data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mce_prob_data = db.filter(climatemodel=\"MCE*PROB*\")\n",
    "mce_prob_data[\"climatemodel\"].unique()\n",
    "if not mce_prob_data.timeseries().empty:\n",
    "    mce_prob_data = mce_prob_data.timeseries().reset_index()\n",
    "\n",
    "    mce_prob_data[\"variable\"] = (\n",
    "        mce_prob_data[\"variable\"]\n",
    "        + \"|\"\n",
    "        + mce_prob_data[\"climatemodel\"].apply(mce_get_quantile)\n",
    "        + \"th quantile\"\n",
    "    )\n",
    "\n",
    "    mce_prob_data[\"climatemodel\"] = mce_prob_data[\"climatemodel\"].apply(\n",
    "        lambda x: \"-\".join(x.split(\"-\")[:-1])\n",
    "    )\n",
    "\n",
    "    db = db.filter(climatemodel=\"MCE*PROB*\", keep=False).append(mce_prob_data)\n",
    "\n",
    "db.filter(climatemodel=\"MCE*PROB\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hector_prob_data = db.filter(climatemodel=\"hector*HISTCALIB*\")\n",
    "if not hector_prob_data.timeseries().empty:\n",
    "    hector_prob_data = hector_prob_data.timeseries().reset_index()\n",
    "\n",
    "    hector_prob_data[\"variable\"] = (\n",
    "        hector_prob_data[\"variable\"]\n",
    "        + \"|\"\n",
    "        + hector_prob_data[\"climatemodel\"].apply(hector_get_quantile)\n",
    "    )\n",
    "\n",
    "    hector_prob_data[\"climatemodel\"] = hector_prob_data[\"climatemodel\"].apply(\n",
    "        lambda x: x.split(\"-\")[0]\n",
    "    )\n",
    "\n",
    "    db = db.filter(climatemodel=\"hector*HISTCALIB*\", keep=False).append(\n",
    "        hector_prob_data\n",
    "    )\n",
    "\n",
    "db.filter(climatemodel=\"hector*HISTCALIB\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_prob_data = db.filter(climatemodel=\"*FaIR*\")\n",
    "if not fair_prob_data.timeseries().empty:\n",
    "    fair_prob_data = fair_prob_data.timeseries().reset_index()\n",
    "\n",
    "    fair_prob_data[\"variable\"] = fair_prob_data[\"variable\"].apply(\n",
    "        lambda x: x.replace(\"|00th\", \"|0th\").replace(\"|05th\", \"|5th\")\n",
    "    )\n",
    "\n",
    "    db = db.filter(climatemodel=\"*FaIR*\", keep=False).append(\n",
    "        ScmDataFrame(fair_prob_data)\n",
    "    )\n",
    "\n",
    "db.filter(climatemodel=\"*FaIR*\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wasp_prob_data = db.filter(climatemodel=\"*WASP*\")\n",
    "if not wasp_prob_data.timeseries().empty:\n",
    "    wasp_prob_data = wasp_prob_data.timeseries().reset_index()\n",
    "\n",
    "    wasp_prob_data[\"variable\"] = wasp_prob_data[\"variable\"].apply(\n",
    "        lambda x: x.replace(\"|00th\", \"|0th\").replace(\"|05th\", \"|5th\")\n",
    "    )\n",
    "\n",
    "    db = db.filter(climatemodel=\"*WASP*\", keep=False).append(\n",
    "        ScmDataFrame(wasp_prob_data)\n",
    "    )\n",
    "\n",
    "db.filter(climatemodel=\"*WASP*\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unify units and check names\n",
    "\n",
    "Here we loop over the submissions and unify their units as well as checking their naming matches what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = db.timeseries()\n",
    "any_failures = False\n",
    "\n",
    "clean_db = []\n",
    "for climatemodel, cdf in tqdm.tqdm_notebook(\n",
    "    base_df.groupby(\"climatemodel\"), desc=\"Climate model\"\n",
    "):\n",
    "    print(climatemodel)\n",
    "    print(\"-\" * len(climatemodel))\n",
    "\n",
    "    any_failures_climatemodel = False\n",
    "\n",
    "    cdf = ScmDataFrame(cdf)\n",
    "    cdf_converted_units = unify_units(cdf, protocol_variables)\n",
    "    try:\n",
    "        check_all_scenarios_as_in_protocol(cdf_converted_units, protocol_scenarios)\n",
    "        check_all_variables_and_units_as_in_protocol(\n",
    "            cdf_converted_units, protocol_variables\n",
    "        )\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        any_failures_climatemodel = True\n",
    "    #     # currently not possible as groups weren't told to obey variable hierarchy,\n",
    "    #     # add this in phase 2\n",
    "    #     for v_top in cdf_converted_units.filter(level=0)[\"variable\"].unique():\n",
    "    #         print(v_top)\n",
    "    #         cdf_pyam = cdf_converted_units.filter(variable=\"{}*\".format(v_top)).timeseries()\n",
    "    #         cdf_pyam.columns = cdf_pyam.columns.map(lambda x: x.year)\n",
    "\n",
    "    #         cdf_consistency_checker = pyam.IamDataFrame(cdf_pyam)\n",
    "    #         if cdf_consistency_checker.check_internal_consistency() is not None:\n",
    "    #             print(\"Failed for {}\".format(v_top))\n",
    "    #             any_failures_climatemodel = True\n",
    "    #             failing_set = cdf_consistency_checker.copy()\n",
    "\n",
    "    print()\n",
    "    if not any_failures_climatemodel:\n",
    "        clean_db.append(cdf_converted_units)\n",
    "        print(\"All clear for {}\".format(climatemodel))\n",
    "    else:\n",
    "        print(\"Failed {}\".format(climatemodel))\n",
    "        print(\"X\" * len(\"Failed\"))\n",
    "        any_failures = True\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "if any_failures:\n",
    "    raise AssertionError(\"database isn't ready yet\")\n",
    "else:\n",
    "    clean_db = df_append(clean_db)\n",
    "    clean_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes whilst doing this:\n",
    "\n",
    "- I wasn't clear that the variable hierarchy needs to be obeyed, hence doing internal consistency checks isn't going to work\n",
    "\n",
    "For phase 2:\n",
    "\n",
    "- checking internal consistency super slow, worth looping over top level variables when doing this to speed up filtering\n",
    "- need to decide what a sensible tolerance is\n",
    "- might have to go back to model notes to work out why there are inconsistencies\n",
    "- will have to implement a custom hack to deal with the double counting in the direct aerosol forcing hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_into_database(clean_db, OUTPUT_DATABASE_PATH, \"rcmip-phase-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
